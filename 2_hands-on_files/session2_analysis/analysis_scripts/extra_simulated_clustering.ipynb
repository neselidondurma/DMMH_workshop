{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "237c2b00",
   "metadata": {},
   "source": [
    "## KMeans Clustering\n",
    "\n",
    "In this script, we will:\n",
    "\n",
    "1. Load and preprocess the dataset.\n",
    "2. Perform KMeans clustering.\n",
    "3. Evaluate clustering using Silhouette Score and Adjusted Rand Index (ARI).\n",
    "4. Visualize cluster-label relationships using heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns   \n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3f20a6",
   "metadata": {},
   "source": [
    "### Task 1: Load the CSV file, define relevant groups, and create dataframes\n",
    "\n",
    "We will categorize the columns into audio features and video features to enable more detailed analysis later in the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "625dd288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV\n",
    "df = pd.read_csv(\"../simulated_processed_data/simulated_data_combined.csv\")\n",
    "\n",
    "# Define columns\n",
    "general_info_cols = [\"id\", \"sex\", \"condition\"]\n",
    "\n",
    "audio_feature_cols = [\n",
    "    \"f0_mean\",\"f0_stddev\",\"f0_range\",\"f1_mean\",\"f1_stddev\",\"f1_range\",\n",
    "    \"f2_mean\",\"f2_stddev\",\"f2_range\",\"f3_mean\",\"f3_stddev\",\"f3_range\",\n",
    "    \"f4_mean\",\"f4_stddev\",\"f4_range\",\"loudness_mean\",\"loudness_stddev\",\"loudness_range\",\n",
    "    \"hnr_mean\",\"hnr_stddev\",\"hnr_range\",\"jitter\",\"jitter_abs\",\"jitter_rap\",\"jitter_ppq5\",\n",
    "    \"jitter_ddp\",\"shimmer\",\"shimmer_db\",\"shimmer_apq3\",\"shimmer_apq5\",\"shimmer_apq11\",\n",
    "    \"shimmer_dda\",\"gne_ratio\",\"mfcc1_mean\",\"mfcc2_mean\",\"mfcc3_mean\",\"mfcc4_mean\",\"mfcc5_mean\",\n",
    "    \"mfcc6_mean\",\"mfcc7_mean\",\"mfcc8_mean\",\"mfcc9_mean\",\"mfcc10_mean\",\"mfcc11_mean\",\"mfcc12_mean\",\n",
    "    \"mfcc13_mean\",\"mfcc14_mean\",\"mfcc1_var\",\"mfcc2_var\",\"mfcc3_var\",\"mfcc4_var\",\"mfcc5_var\",\n",
    "    \"mfcc6_var\",\"mfcc7_var\",\"mfcc8_var\",\"mfcc9_var\",\"mfcc10_var\",\"mfcc11_var\",\"mfcc12_var\",\n",
    "    \"mfcc13_var\",\"mfcc14_var\",\"cpp_mean\",\"cpp_var\",\"spir\",\"dur_med\",\"dur_mad\",\"silence_ratio\",\n",
    "    \"rel_f0_sd\",\"rel_se0_sd\"\n",
    "]\n",
    "\n",
    "video_feature_cols = [\n",
    "    \"anger_mean\",\"disgust_mean\",\"fear_mean\",\"happiness_mean\",\"sadness_mean\",\"surprise_mean\",\n",
    "    \"neutral_mean\",\"AU01_mean\",\"AU02_mean\",\"AU04_mean\",\"AU05_mean\",\"AU06_mean\",\"AU07_mean\",\n",
    "    \"AU09_mean\",\"AU10_mean\",\"AU11_mean\",\"AU12_mean\",\"AU14_mean\",\"AU15_mean\",\"AU17_mean\",\n",
    "    \"AU20_mean\",\"AU23_mean\",\"AU24_mean\",\"AU25_mean\",\"AU26_mean\",\"AU28_mean\",\"AU43_mean\",\n",
    "    \"mouth_openness_mean\",\"anger_std\",\"disgust_std\",\"fear_std\",\"happiness_std\",\"sadness_std\",\n",
    "    \"surprise_std\",\"neutral_std\",\"AU01_std\",\"AU02_std\",\"AU04_std\",\"AU05_std\",\"AU06_std\",\"AU07_std\",\n",
    "    \"AU09_std\",\"AU10_std\",\"AU11_std\",\"AU12_std\",\"AU14_std\",\"AU15_std\",\"AU17_std\",\"AU20_std\",\n",
    "    \"AU23_std\",\"AU24_std\",\"AU25_std\",\"AU26_std\",\"AU28_std\",\"AU43_std\",\"mouth_openness_std\"\n",
    "]\n",
    "\n",
    "# Create separate DataFrames\n",
    "audio_df = df[general_info_cols + audio_feature_cols]\n",
    "video_df = df[general_info_cols + video_feature_cols]\n",
    "combined_df = df[general_info_cols + audio_feature_cols + video_feature_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbf82b0",
   "metadata": {},
   "source": [
    "### Task 2: Preprocess the data\n",
    "\n",
    "Follow the steps:\n",
    "\n",
    "1. Separate features and target (and drop metadata columns)\n",
    "2. Impute missing values (sklearn - SimpleImputer) - K-Means cannot handle NaN or missing values; distance computations fail if any feature is missing.\n",
    "3. Scale features (sklearn - StandardScaler) - If features are on different scales, those with larger numerical ranges dominate the distance calculation, which can skew the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40eb3279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a function for preprocessing data\n",
    "def preprocess_data(df, target, metadata_cols=[\"id\", \"condition\",\"sex\"]):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset for modeling - drop metadata columns, separate features and target, impute missing values, and scale features\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataset\n",
    "        target_col (str): Name of the target column\n",
    "        metadata_cols (list, optional): Columns to drop\n",
    "\n",
    "    Returns:\n",
    "        X_scaled (np.ndarray): Scaled feature matrix\n",
    "        y (np.ndarray): target labels\n",
    "    \"\"\"\n",
    "\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2f0cf8",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><span style=\"font-size:20px; color:darkgoldenrod; font-weight:bold;\">Click to see the solution</span></summary>\n",
    "\n",
    "```python\n",
    "def preprocess_data(df, target, metadata_cols=[\"id\", \"condition\",\"sex\"]):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset for modeling - drop metadata columns, separate features and target, impute missing values, and scale features\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataset\n",
    "        target_col (str): Name of the target column\n",
    "        metadata_cols (list, optional): Columns to drop\n",
    "\n",
    "    Returns:\n",
    "        X_scaled (np.ndarray): Scaled feature matrix\n",
    "        y (np.ndarray): target labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Separate target and features\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=metadata_cols)\n",
    "\n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "    return X_scaled, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d385fb28",
   "metadata": {},
   "source": [
    "### Task 3: KMeans Clustering \n",
    "\n",
    "Perform KMeans clustering and evaluate the clusters using:\n",
    "\n",
    "üìå In unsupervised learning, we typically don‚Äôt know how many clusters exist in the data, so various methods are used to estimate an appropriate number.\n",
    "\n",
    "For this exercise, though, we already know the number of labels. So we‚Äôll try using that number as our cluster count and see how well K-Means can group the data. \n",
    "\n",
    "Silhouette Score ‚Üí how well-separated the clusters are (sklearn.metrics - silhouette_score)\n",
    "\n",
    "Adjusted Rand Index (ARI) ‚Üí how well clusters match a known categorical label (sklearn.metrics - adjusted_rand_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a862ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a function for kmeans clustering\n",
    "def kmeans_clustering(df, X_scaled, y):\n",
    "    \"\"\"\n",
    "    Perform KMeans clustering on preprocessed features and evaluate against a categorical label\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Original dataframe containing features and labels\n",
    "        X_scaled (np.ndarray): Standardized feature matrix\n",
    "        y (pd.Series): Categorical target labels to compare clusters against\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Copy of the original dataframe with an added 'cluster' column.\n",
    "    \n",
    "    Prints:\n",
    "        Silhouette Score: Measures cluster cohesion (range [-1, 1], higher is better).\n",
    "        Adjusted Rand Index (ARI): Measures agreement between predicted clusters and true labels (range [-1, 1], higher is better).\n",
    "    \"\"\"\n",
    "\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9a9adb",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><span style=\"font-size:20px; color:darkgoldenrod; font-weight:bold;\">Click to see the solution</span></summary>\n",
    "\n",
    "```python\n",
    "def kmeans_clustering(df, X_scaled, y):\n",
    "    \"\"\"\n",
    "    Perform KMeans clustering on preprocessed features and evaluate against a categorical label\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Original dataframe containing features and labels\n",
    "        X_scaled (np.ndarray): Standardized feature matrix\n",
    "        y (pd.Series): Categorical target labels to compare clusters against\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Copy of the original dataframe with an added 'cluster' column.\n",
    "    \n",
    "    Prints:\n",
    "        Silhouette Score: Measures cluster cohesion (range [-1, 1], higher is better).\n",
    "        Adjusted Rand Index (ARI): Measures agreement between predicted clusters and true labels (range [-1, 1], higher is better).\n",
    "    \"\"\"\n",
    "\n",
    "   \n",
    "    n_clusters = len(y.unique())\n",
    "    \n",
    "    # Fit KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Attach clusters to df copy\n",
    "    df_out = df.copy()\n",
    "    df_out[\"cluster\"] = clusters\n",
    "    \n",
    "    # Evaluate clustering\n",
    "    sil_score = silhouette_score(X_scaled, clusters)\n",
    "    ari_score = adjusted_rand_score(y, clusters)\n",
    "    print(f\"Silhouette Score: {sil_score:.3f}\")\n",
    "    print(f\"Adjusted Rand Index: {ari_score:.3f}\")\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e973f524",
   "metadata": {},
   "source": [
    "### Task 4: Cluster Visualization\n",
    "\n",
    "Visualize the clustering results using a heatmap showing the proportion of each label in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d89b49ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_results(df_out, target_label, dataset_name):\n",
    "    \"\"\"\n",
    "    Plot the clustering results as a heatmap showing the proportion of each label in each cluster.\n",
    "\n",
    "    Args:\n",
    "        df_out (pd.DataFrame): DataFrame containing a 'cluster' column and the target label column.\n",
    "        target_label (str): Name of the categorical label to compare clusters against \n",
    "        dataset_name (str): Name of the dataset for labeling the plot title.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Displays:\n",
    "        A heatmap showing the proportion of each target label within each cluster.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Heatmap of cluster vs label proportions\n",
    "        confusion = pd.crosstab(df_out[\"cluster\"], df_out[target_label])\n",
    "        confusion_norm = confusion.div(confusion.sum(axis=1), axis=0)\n",
    "        \n",
    "        plt.figure(figsize=(10, 4))\n",
    "        sns.heatmap(confusion_norm, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
    "        plt.title(f\"{dataset_name}: Cluster vs {target_label} Proportions\")\n",
    "        plt.ylabel(\"Cluster\")\n",
    "        plt.xlabel(target_label.capitalize())\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"[Warning] Could not plot\")\n",
    "        print(\"Most likely the code is not yet complete (complete the cells with TODO).\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab0d024",
   "metadata": {},
   "source": [
    "### Task 5: Apply Clustering to Combined Features\n",
    "\n",
    "Cluster by condition (emotion) and sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de8cf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Could not plot\n",
      "Most likely the code is not yet complete (complete the cells with TODO).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_emo_combined, y_emo_combined = preprocess_data(combined_df, \"condition\")\n",
    "df_out_combined = kmeans_clustering(combined_df, X_emo_combined, y_emo_combined)\n",
    "plot_cluster_results(df_out_combined, \"condition\", \"Combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30d91ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Could not plot\n",
      "Most likely the code is not yet complete (complete the cells with TODO).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_sex_combined, y_sex_combined = preprocess_data(combined_df, \"sex\")\n",
    "df_out_combined = kmeans_clustering(combined_df, X_sex_combined, y_sex_combined)\n",
    "plot_cluster_results(df_out_combined, \"sex\", \"Combined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6fde10",
   "metadata": {},
   "source": [
    "### Insights?\n",
    "üïµÔ∏è Which clusters appear more consistent with the labels? Next, evaluate if seperating video and audio features can result in better clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5253cd",
   "metadata": {},
   "source": [
    "### Task 6: Apply Clustering to Video Features\n",
    "\n",
    "Cluster by condition (emotion) and sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ceb2a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Could not plot\n",
      "Most likely the code is not yet complete (complete the cells with TODO).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_emo_video, y_emo_video = preprocess_data(video_df, \"condition\")\n",
    "df_out_video = kmeans_clustering(video_df, X_emo_video, y_emo_video)\n",
    "plot_cluster_results(df_out_video, \"condition\", \"Video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f3232c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Could not plot\n",
      "Most likely the code is not yet complete (complete the cells with TODO).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_sex_video, y_sex_video = preprocess_data(video_df, \"sex\")\n",
    "df_out_video = kmeans_clustering(video_df, X_sex_video, y_sex_video)\n",
    "plot_cluster_results(df_out_video, \"sex\", \"Video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fbfd5d",
   "metadata": {},
   "source": [
    "### Insights?\n",
    "ü§î Are clusters based on video features better at separating emotions or sex?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b615f8da",
   "metadata": {},
   "source": [
    "### Task 7: Apply Clustering to Audio Features\n",
    "\n",
    "Cluster by condition (emotion) and sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "752821df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Could not plot\n",
      "Most likely the code is not yet complete (complete the cells with TODO).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_emo_audio, y_emo_audio = preprocess_data(audio_df, \"condition\")\n",
    "df_out_audio = kmeans_clustering(audio_df, X_emo_audio, y_emo_audio)\n",
    "plot_cluster_results(df_out_audio, \"condition\", \"Audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10f9cfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Could not plot\n",
      "Most likely the code is not yet complete (complete the cells with TODO).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_sex_audio, y_sex_audio = preprocess_data(audio_df, \"sex\")\n",
    "df_out_audio = kmeans_clustering(audio_df, X_sex_audio, y_sex_audio)\n",
    "plot_cluster_results(df_out_audio, \"sex\", \"Audio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b69d24",
   "metadata": {},
   "source": [
    "### Insights?\n",
    "üßê Are clusters based on audio features better at separating emotions or sex, and why might that be?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
